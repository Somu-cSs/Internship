{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb92445",
   "metadata": {},
   "source": [
    "# Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "26973942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time   #use to stop search engine for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bc71e58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# opening the webpage on automated browser\n",
    "driver.get(\"https://www.shine.com/\")                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "895ccf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to Close the pop-up window\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8d63687e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entering Designation and location as per questoin\n",
    "#Job title\n",
    "desig = driver.find_element(By.CLASS_NAME,\"searchBarInput\")\n",
    "desig.send_keys(\"Data Analyst\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3e4207a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#search1\n",
    "\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/header[2]/div[2]/div[1]/span\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3038e7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Job title1\n",
    "desig = driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "c=desig.send_keys(\"Data Analyst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a4a18243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Selecting the text from listed bar\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div[2]/div[2]\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9e1747c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location input \n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fb5d6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8d32928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to each attribute\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8ba3f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Trying to Close the pop-up window\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "471b05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the Job title\n",
    "# Locate elements by tag name\n",
    "elements_with_tag_name = driver.find_elements(By.TAG_NAME, 'h2')\n",
    "\n",
    "for i in elements_with_tag_name[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9d0f14c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Coordinator (Data Analyst)',\n",
       " 'Data Analyst - Java/Python',\n",
       " 'Hiring For Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst Urgent Recruiment',\n",
       " 'How relevant did you find the job search results ?',\n",
       " 'Apply Now a Data Analyst',\n",
       " 'Apply Now Data Analyst',\n",
       " 'Needed for Data Analyst']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "06640b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the company name\n",
    "#company_tags = driver.find_element(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "span_elements = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "\n",
    "# Extract text from each <span> element\n",
    "span_texts = [span.text for span in span_elements]\n",
    "\n",
    "# Print the extracted text\n",
    "for text in span_texts[0:10]:\n",
    "    company_name.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c2578e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2 to 4 Yrs\\nBangalore', '3 to 6 Yrs\\nBangalore', '0 to 4 Yrs\\nBangalore\\n+14', '2 to 5 Yrs\\nBangalore', '7 to 12 Yrs\\nBangalore\\n+9', '0 to 4 Yrs\\nBangalore\\n+14', '1 to 2 Yrs\\nBangalore', '1 to 2 Yrs\\nBangalore', '1 to 2 Yrs\\nBangalore', '1 to 2 Yrs\\nBangalore']\n"
     ]
    }
   ],
   "source": [
    "#Scraping the Job location & Experience\n",
    "\n",
    "location_experience = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_lists__fdnsc\"]')\n",
    "\n",
    "# Initialize a list to store experience & job locations\n",
    "experience_locations = []\n",
    "\n",
    "# Iterate over the location elements\n",
    "for element in location_experience[0:10]:\n",
    "    exloc = element.text\n",
    "    experience_locations.append(exloc)\n",
    "\n",
    "# Print the list of job locations\n",
    "print(experience_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f8a08d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiences:\n",
      "['2 to 4 Yrs', '3 to 6 Yrs', '0 to 4 Yrs', '2 to 5 Yrs', '7 to 12 Yrs', '0 to 4 Yrs', '1 to 2 Yrs', '1 to 2 Yrs', '1 to 2 Yrs', '1 to 2 Yrs']\n",
      "\n",
      "Locations:\n",
      "['Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore']\n"
     ]
    }
   ],
   "source": [
    "# Spliting experience & location into different lists\n",
    "\n",
    "for item in experience_locations:\n",
    "    parts = item.split('\\n')\n",
    "    experience = parts[0]\n",
    "    location = parts[1]\n",
    "    experience_required.append(experience)\n",
    "    job_location.append(location)\n",
    "\n",
    "print(\"Experiences:\")\n",
    "print(experience_required)\n",
    "\n",
    "print(\"\\nLocations:\")\n",
    "print(job_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "005f5b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),\n",
    "      len(job_location),\n",
    "      len(company_name),\n",
    "      len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c46a47d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Coordinator (Data Analyst)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>futures and careers</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Java/Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ashutosh sabhashankar chaturvedi hi...</td>\n",
       "      <td>7 to 12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst Urgent Recruiment</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How relevant did you find the job search resul...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apply Now a Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apply Now Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Needed for Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title Job Location  \\\n",
       "0                 Project Coordinator (Data Analyst)    Bangalore   \n",
       "1                         Data Analyst - Java/Python    Bangalore   \n",
       "2                            Hiring For Data Analyst    Bangalore   \n",
       "3                                Senior Data Analyst    Bangalore   \n",
       "4                                       Data Analyst    Bangalore   \n",
       "5                     Data Analyst Urgent Recruiment    Bangalore   \n",
       "6  How relevant did you find the job search resul...    Bangalore   \n",
       "7                           Apply Now a Data Analyst    Bangalore   \n",
       "8                             Apply Now Data Analyst    Bangalore   \n",
       "9                            Needed for Data Analyst    Bangalore   \n",
       "\n",
       "                             Company name Experience Required  \n",
       "0                     futures and careers          2 to 4 Yrs  \n",
       "1  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "2                kavya staffing solutions          0 to 4 Yrs  \n",
       "3           ara resources private limited          2 to 5 Yrs  \n",
       "4  ashutosh sabhashankar chaturvedi hi...         7 to 12 Yrs  \n",
       "5                       divya interprises          0 to 4 Yrs  \n",
       "6       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "7       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "8       deuglo infosystem private limited          1 to 2 Yrs  \n",
       "9       deuglo infosystem private limited          1 to 2 Yrs  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating a DataFrame & converting into csv file     \n",
    "df =pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company name': company_name, 'Experience Required':experience_required})\n",
    "df.to_csv('Q1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dedcd02",
   "metadata": {},
   "source": [
    "# Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a31cfc89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# opening the webpage on automated browser\n",
    "driver.get(\"https://www.shine.com/\")                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3d237b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to Close the pop-up window\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "512ca648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entering Designation and location as per questoin\n",
    "#Job title\n",
    "desig = driver.find_element(By.CLASS_NAME,\"searchBarInput\")\n",
    "desig.send_keys(\"Data Scientist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "07698693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search1\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/header[2]/div[2]/div[1]/span\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a694ba71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Job title1\n",
    "desig = driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "desig.send_keys(\"Data Scientist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2253baef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Job title1\n",
    "desig = driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "desig.send_keys(\"Data Scientist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "816d7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the text from listed bar\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/ul/li[4]\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c041b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location input \n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cdebdbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for results\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5aacbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to each attribute\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8d626473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Trying to Close the pop-up window\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2dfffe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the Job title\n",
    "# Locate elements by tag name\n",
    "elements_with_tag_name = driver.find_elements(By.TAG_NAME, 'h2')\n",
    "\n",
    "for i in elements_with_tag_name[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1af3ea5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2 to 4 Yrs\\nBangalore', '3 to 6 Yrs\\nBangalore', '0 to 4 Yrs\\nBangalore\\n+14', '2 to 5 Yrs\\nBangalore', '7 to 12 Yrs\\nBangalore\\n+9', '0 to 4 Yrs\\nBangalore\\n+14', '1 to 2 Yrs\\nBangalore', '1 to 2 Yrs\\nBangalore', '1 to 2 Yrs\\nBangalore', '1 to 2 Yrs\\nBangalore']\n"
     ]
    }
   ],
   "source": [
    "#Scraping the Job location & Experience\n",
    "\n",
    "location_experience = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_lists__fdnsc\"]')\n",
    "\n",
    "# Initialize a list to store experience & job locations\n",
    "experience_locations = []\n",
    "\n",
    "# Iterate over the location elements\n",
    "for element in location_elements[0:10]:\n",
    "    exloc = element.text\n",
    "    experience_locations.append(exloc)\n",
    "\n",
    "# Print the list of job locations\n",
    "print(experience_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6bf6e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiences:\n",
      "['2 to 4 Yrs', '3 to 6 Yrs', '0 to 4 Yrs', '2 to 5 Yrs', '7 to 12 Yrs', '0 to 4 Yrs', '1 to 2 Yrs', '1 to 2 Yrs', '1 to 2 Yrs', '1 to 2 Yrs']\n",
      "\n",
      "Locations:\n",
      "['Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore']\n"
     ]
    }
   ],
   "source": [
    "# Spliting experience & location into different lists\n",
    "\n",
    "for item in experience_locations:\n",
    "    parts = item.split('\\n')\n",
    "    experience = parts[0]\n",
    "    location = parts[1]\n",
    "    experience_required.append(experience)\n",
    "    job_location.append(location)\n",
    "\n",
    "print(\"Experiences:\")\n",
    "print(experience_required)\n",
    "\n",
    "print(\"\\nLocations:\")\n",
    "print(job_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2123427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the company name\n",
    "#company_tags = driver.find_element(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "span_elements = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "\n",
    "# Extract text from each <span> element\n",
    "span_texts = [span.text for span in span_elements]\n",
    "\n",
    "# Print the extracted text\n",
    "for text in span_texts[0:10]:\n",
    "    company_name.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "47b493e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking for the s length\n",
    "print(len(job_title),\n",
    "      len(job_location),\n",
    "      len(company_name),\n",
    "      len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aa3258a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>kavya staffing solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Urgent Recruitment</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>divya interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Required for Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgently need Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How relevant did you find the job search resul...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>seven geomax consulting private lim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data scientist Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>employberry consultants hiring for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>niharika enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>deuglo infosystem private limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title Job Location  \\\n",
       "0                          Hiring For Data Scientist    Bangalore   \n",
       "1                          Hiring For Data Scientist    Bangalore   \n",
       "2                                     Data Scientist    Bangalore   \n",
       "3                  Data Scientist Urgent Recruitment    Bangalore   \n",
       "4                        Required for Data Scientist    Bangalore   \n",
       "5                       Urgently need Data Scientist    Bangalore   \n",
       "6  How relevant did you find the job search resul...    Bangalore   \n",
       "7                           Data scientist Bangalore    Bangalore   \n",
       "8                                     Data Scientist    Bangalore   \n",
       "9                          Hiring For Data Scientist    Bangalore   \n",
       "\n",
       "                             Company name  \n",
       "0                kavya staffing solutions  \n",
       "1                kavya staffing solutions  \n",
       "2                     skyleaf consultants  \n",
       "3                       divya interprises  \n",
       "4       deuglo infosystem private limited  \n",
       "5       deuglo infosystem private limited  \n",
       "6  seven geomax consulting private lim...  \n",
       "7  employberry consultants hiring for ...  \n",
       "8                    niharika enterprises  \n",
       "9       deuglo infosystem private limited  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating a DataFrame & converting into csv file     \n",
    "df =pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company name': company_name})\n",
    "df.to_csv('Q2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6135555",
   "metadata": {},
   "source": [
    "# Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3632bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# opening the webpage on automated browser\n",
    "driver.get(\"https://www.shine.com/\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "28e2f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a sleep to give time for results to load\n",
    "time.sleep(10)\n",
    "\n",
    "#Trying to Close the pop-up window\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6f825f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entering Designation and location as per questoin\n",
    "#Job title\n",
    "desig = driver.find_element(By.CLASS_NAME,\"searchBarInput\")\n",
    "desig.send_keys(\"Data Scientist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "68fbd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search1\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/header[2]/div[2]/div[1]/span\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4e39e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job title1\n",
    "desig = driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "desig.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1f5fed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location input \n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys(\"Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a731e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for results\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1fc005d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Trying to Close the pop-up window\n",
    "time.sleep(10)\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "58e72899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying salary filter 3-6 lakhs\n",
    "salary_filter = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div/ul/li[3]/button\")\n",
    "salary_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1589dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the filter\n",
    "filter = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label\")\n",
    "filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "88c1bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[4]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]\")\n",
    "results.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "03a77696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since every filter is set as per the given question, Now we can extract the data.\n",
    "\n",
    "#creating empty list to each attribute\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b506dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_required=[]\n",
    "job_location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f47103f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the Job title\n",
    "# Locate elements by tag name\n",
    "elements_with_tag_name = driver.find_elements(By.TAG_NAME, 'h2')\n",
    "\n",
    "for i in elements_with_tag_name[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "569f159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 to 3 Yrs\\nDelhi\\n+6', '3 to 6 Yrs\\nDelhi', '0 to 1 Yr\\nDelhi\\n+6', '0 to 2 Yrs\\nGurugram', '3 to 5 Yrs\\nDelhi\\n+4', '2 to 3 Yrs\\nDelhi', '2 to 3 Yrs\\nDelhi', '1 to 2 Yrs\\nNoida', '1 to 2 Yrs\\nNoida', '2 to 6 Yrs\\nNoida']\n"
     ]
    }
   ],
   "source": [
    "#Scraping the Job location & Experience\n",
    "\n",
    "loc_exp= driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_lists__fdnsc\"]')\n",
    "\n",
    "# Initialize a list to store experience & job locations\n",
    "experience_locations = []\n",
    "\n",
    "# Iterate over the location elements\n",
    "for element in loc_exp[0:10]:\n",
    "    exloc = element.text\n",
    "    experience_locations.append(exloc)\n",
    "\n",
    "# Print the list of job locations\n",
    "print(experience_locations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7fc83059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiences:\n",
      "['0 to 3 Yrs', '3 to 6 Yrs', '0 to 1 Yr', '0 to 2 Yrs', '3 to 5 Yrs', '2 to 3 Yrs', '2 to 3 Yrs', '1 to 2 Yrs', '1 to 2 Yrs', '2 to 6 Yrs']\n",
      "\n",
      "Locations:\n",
      "['Delhi', 'Delhi', 'Delhi', 'Gurugram', 'Delhi', 'Delhi', 'Delhi', 'Noida', 'Noida', 'Noida']\n"
     ]
    }
   ],
   "source": [
    "# Spliting experience & location into different lists\n",
    "\n",
    "for item in experience_locations:\n",
    "    parts = item.split('\\n')\n",
    "    experience = parts[0]\n",
    "    location = parts[1]\n",
    "    experience_required.append(experience)\n",
    "    job_location.append(location)\n",
    "\n",
    "print(\"Experiences:\")\n",
    "print(experience_required)\n",
    "\n",
    "print(\"\\nLocations:\")\n",
    "print(job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "35c27d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scraping the company name\n",
    "#company_tags = driver.find_element(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "span_elements = driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "\n",
    "# Extract text from each <span> element\n",
    "span_texts = [span.text for span in span_elements]\n",
    "\n",
    "# Print the extracted text\n",
    "for text in span_texts[0:10]:\n",
    "    company_name.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "594b46f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \n",
    "#checking for the same length\n",
    "print(len(job_title),\n",
    "      len(job_location),\n",
    "      len(company_name),\n",
    "      len(experience_required))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4c5b8f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>skyleaf consultants</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>pro career ignition hr consultancy ...</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How relevant did you find the job search resul...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>nina s hr consultancy</td>\n",
       "      <td>2 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for _GCP Data Engineer/Lead/Architect- Delhi</td>\n",
       "      <td>Noida</td>\n",
       "      <td>ntt global networks</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Modeling Analyst</td>\n",
       "      <td>Noida</td>\n",
       "      <td>ntt global networks</td>\n",
       "      <td>1 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Risk Analyst-QE</td>\n",
       "      <td>Noida</td>\n",
       "      <td>ntt global networks</td>\n",
       "      <td>2 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title Job Location  \\\n",
       "0                                     Data Scientist        Delhi   \n",
       "1                                     Data Scientist        Delhi   \n",
       "2                                     Data Scientist        Delhi   \n",
       "3                                     Data Scientist     Gurugram   \n",
       "4                                     Data Scientist        Delhi   \n",
       "5       for _GCP Data Engineer/Lead/Architect- Delhi        Delhi   \n",
       "6  How relevant did you find the job search resul...        Delhi   \n",
       "7       for _GCP Data Engineer/Lead/Architect- Delhi        Noida   \n",
       "8                                   Modeling Analyst        Noida   \n",
       "9                                    Risk Analyst-QE        Noida   \n",
       "\n",
       "                             Company name Experience Required  \n",
       "0                         quiscon biotech          0 to 3 Yrs  \n",
       "1                     skyleaf consultants          3 to 6 Yrs  \n",
       "2                         quiscon biotech           0 to 1 Yr  \n",
       "3  pro career ignition hr consultancy ...          0 to 2 Yrs  \n",
       "4           acme services private limited          3 to 5 Yrs  \n",
       "5                   nina s hr consultancy          2 to 3 Yrs  \n",
       "6                   nina s hr consultancy          2 to 3 Yrs  \n",
       "7                     ntt global networks          1 to 2 Yrs  \n",
       "8                     ntt global networks          1 to 2 Yrs  \n",
       "9                     ntt global networks          2 to 6 Yrs  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating a DataFrame & converting into csv file     \n",
    "df =pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company name': company_name, 'Experience Required':experience_required})\n",
    "df.to_csv('Q3.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b936e4",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c16c471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# opening the webpage on automated browser\n",
    "driver.get(\"https://www.flipkart.com/\")                \n",
    "\n",
    "#Trying to Close the Login pop-up window\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "fbc6a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#waiting to clear login icon\n",
    "time.sleep(3)\n",
    "\n",
    "# Entering the product name and search for it\n",
    "search_product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_product.send_keys(\"sunglasses\")\n",
    "\n",
    "#Searching in the search_bar\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f42672b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store scraped data\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "discounts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b044e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from multiple pages until you get 100 sunglasses\n",
    "num_products = 100\n",
    "products_scraped = 0\n",
    "\n",
    "while products_scraped < num_products:\n",
    "    # Find all the products on the page\n",
    "    products = driver.find_elements(By.CLASS_NAME, '_2WkVRV')\n",
    "    \n",
    "    for product in products:\n",
    "        brand = product.text\n",
    "        brands.append(brand)\n",
    "        \n",
    "        # Find the parent (container) element of the product listing card\n",
    "        # Navigate up two levels to reach the grandparent element that holds more details\n",
    "        parent = product.find_element(By.XPATH, \"./../../..\")\n",
    "        \n",
    "        description = parent.find_element(By.CLASS_NAME, 'IRpwTa').text\n",
    "        descriptions.append(description)\n",
    "        \n",
    "        price = parent.find_element(By.CLASS_NAME, '_30jeq3').text\n",
    "        prices.append(price)\n",
    "        \n",
    "        try:\n",
    "            discount = parent.find_element(By.CLASS_NAME, '_3Ay6Sb').text\n",
    "        except:\n",
    "            discount = \"No Discount\"\n",
    "        discounts.append(discount)\n",
    "        \n",
    "        products_scraped += 1\n",
    "        if products_scraped >= num_products:\n",
    "            break\n",
    "    \n",
    "    # Go to the next page if not the last page\n",
    "    if products_scraped < num_products:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "        next_button.click()\n",
    "        time.sleep(2)  # Give time for the page to load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "dca789e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Brand                                        Description Price  \\\n",
      "0   VINCENT CHASE  UV Protection, Polarized Over-sized Sunglasses...  â‚¹899   \n",
      "1       ROYAL SON  UV Protection Rectangular, Retro Square Sungla...  â‚¹497   \n",
      "2            SRPM             UV Protection Wayfarer Sunglasses (50)  â‚¹204   \n",
      "3          PIRASO           UV Protection Clubmaster Sunglasses (54)  â‚¹239   \n",
      "4       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...  â‚¹179   \n",
      "..            ...                                                ...   ...   \n",
      "95           BKGE  Polarized, UV Protection Retro Square Sunglass...  â‚¹197   \n",
      "96   Singco India          UV Protection Rectangular Sunglasses (55)  â‚¹502   \n",
      "97  VINCENT CHASE     Polarized, UV Protection Round Sunglasses (51)  â‚¹965   \n",
      "98     SmartGlass       UV Protection Aviator Sunglasses (Free Size)  â‚¹429   \n",
      "99        ROADWAY  UV Protection Wayfarer, Sports, Spectacle , Re...  â‚¹294   \n",
      "\n",
      "   Discount  \n",
      "0   55% off  \n",
      "1   66% off  \n",
      "2   84% off  \n",
      "3   85% off  \n",
      "4   70% off  \n",
      "..      ...  \n",
      "95  80% off  \n",
      "96  74% off  \n",
      "97  43% off  \n",
      "98  57% off  \n",
      "99  77% off  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the scraped data & converting into csv file \n",
    "data = {\n",
    "    'Brand': brands,\n",
    "    'Description': descriptions,\n",
    "    'Price': prices,\n",
    "    'Discount': discounts\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('sunglasses_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7039439",
   "metadata": {},
   "source": [
    "# Q5\n",
    "# Since the given \"link\" is not working I will be going through General search for \"iPhone-11 (Black,128GB)\" & use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0383ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#link = https://www.flipkart.com/apple-iphone-11-black-128-gb/p/itm8244e8d955aba?pid=MOBFWQ6BKRYBP5X8&lid=LSTMOBFWQ6BKRYBP5X8HS0EXP&marketplace=FLIPKART&q=iphone+11+black&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=Search&iid=dbe2a4cd-5295-4d62-8278-55ad0b5eeb32.MOBFWQ6BKRYBP5X8.SEARCH&ppt=sp&ppn=sp&ssid=f2hcmebni80000001693141679655&qH=77772a3e6366cdf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "723e9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-128-gb/p/itm8244e8d955aba?pid=MOBFWQ6BKRYBP5X8&lid=LSTMOBFWQ6BKRYBP5X8HS0EXP&marketplace=FLIPKART&q=iphone+11+black&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=Search&iid=dbe2a4cd-5295-4d62-8278-55ad0b5eeb32.MOBFWQ6BKRYBP5X8.SEARCH&ppt=sp&ppn=sp&ssid=f2hcmebni80000001693141679655&qH=77772a3e6366cdf8')\n",
    "\n",
    "#waiting to load the page\n",
    "time.sleep(2)\n",
    "\n",
    "#Trying to Close the Login pop-up window\n",
    "\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Wait for the \"All 11391 reviews\" link to be clickable\n",
    "all_reviews_link = driver.find_element(By.XPATH, '//div[@class=\"_3UAT2v _16PBlm\"]//span[contains(text(), \"All 11391 reviews\")]')\n",
    "all_reviews_link.click()\n",
    "\n",
    "# Initialize lists to store scraped data\n",
    "ratings = []\n",
    "review_summaries = []\n",
    "full_reviews = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "442d5e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rating       Review Summary  \\\n",
      "0      5       Classy product   \n",
      "1      5       Classy product   \n",
      "2      5             Terrific   \n",
      "3      5            Wonderful   \n",
      "4      5     Perfect product!   \n",
      "5      5    Worth every penny   \n",
      "6      5  Best in the market!   \n",
      "7      5            Just wow!   \n",
      "8      5            Fabulous!   \n",
      "9      5        Great product   \n",
      "\n",
      "                                         Full Review  \n",
      "0                                       Photos super  \n",
      "1  Camera is awesome\\nBest battery backup\\nA perf...  \n",
      "2                                     Very very good  \n",
      "3                             This is amazing at all  \n",
      "4                                         V Good all  \n",
      "5  Feeling awesome after getting the delivery of ...  \n",
      "6                                        Good Camera  \n",
      "7                                  Perfect Product!!  \n",
      "8                    SuperðŸ”¥ and good performance ðŸ‘Œâ¤ï¸  \n",
      "9                                     Purple is best  \n"
     ]
    }
   ],
   "source": [
    "# Scrape data from the review elements\n",
    "num_reviews = 100\n",
    "while len(ratings) < num_reviews:\n",
    "    review_elements = driver.find_elements(By.CLASS_NAME, '_2-N8zT')\n",
    "\n",
    "    for review in review_elements:\n",
    "        if len(ratings) >= num_reviews:\n",
    "            break\n",
    "\n",
    "        parent = review.find_element(By.XPATH, \"./../../..\")\n",
    "\n",
    "        try:\n",
    "            rating = parent.find_element(By.CLASS_NAME, '_3LWZlK._1BLPMq').text\n",
    "        except:\n",
    "            rating = 'No Rating'\n",
    "        ratings.append(rating)\n",
    "\n",
    "        review_summary = review.text\n",
    "        review_summaries.append(review_summary)\n",
    "\n",
    "        # Store the full review text before clicking \"Read more\"\n",
    "        try:\n",
    "            full_review_text = parent.find_element(By.CLASS_NAME, 't-ZTKy').text\n",
    "        except:\n",
    "            full_review_text = 'No Full Review'\n",
    "\n",
    "        try:\n",
    "            read_more = parent.find_element(By.CLASS_NAME, '_1BWGvX')\n",
    "            read_more.click()\n",
    "\n",
    "            # Wait for the full review element to load\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Get the full review text after clicking \"Read more\"\n",
    "            try:\n",
    "                full_review = parent.find_element(By.CLASS_NAME, 't-ZTKy').text\n",
    "            except:\n",
    "                full_review = full_review_text  # Use the stored text if not found\n",
    "\n",
    "        except:\n",
    "            full_review = full_review_text  # Use the stored text if \"Read more\" is not found\n",
    "\n",
    "        full_reviews.append(full_review)\n",
    "    \n",
    "    # Go to the next page if there are more reviews\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, '_3fVaIS')\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "    # Give time for the page to load\n",
    "    time.sleep(2)\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    'Rating': ratings,\n",
    "    'Review Summary': review_summaries,\n",
    "    'Full Review': full_reviews\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e22578",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ade06a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "#waiting to load the page\n",
    "time.sleep(3)\n",
    "\n",
    "#Trying to Close the Login pop-up window\n",
    "\n",
    "try:\n",
    "    search = driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/button\")\n",
    "    search.click()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d218ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Search for \"sneakers\"\n",
    "#waiting to clear login icon\n",
    "time.sleep(3)\n",
    "\n",
    "# Entering the product name and search for it\n",
    "search_product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_product.send_keys(\"sneakers\")\n",
    "\n",
    "#Searching in the search_bar\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cfdfd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store scraped data\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "0cc54103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data for the first 100 sneakers\n",
    "num_sneakers = 100\n",
    "products_scrapped = 0\n",
    "while products_scrapped < num_sneakers:\n",
    "    products = driver.find_elements(By.CLASS_NAME, '_2WkVRV')\n",
    "    descriptions_elements = driver.find_elements(By.CLASS_NAME, 'IRpwTa')\n",
    "    prices_elements = driver.find_elements(By.CLASS_NAME, '_30jeq3')\n",
    "    \n",
    "    for product, description_element, price_element in zip(products, descriptions_elements, prices_elements):\n",
    "        if products_scrapped >= num_sneakers:\n",
    "            break  # Exit the loop if 100 products have been scraped\n",
    "        \n",
    "        brand = product.text\n",
    "        description = description_element.text\n",
    "        price = price_element.text\n",
    "        \n",
    "        brands.append(brand)\n",
    "        descriptions.append(description)\n",
    "        prices.append(price)\n",
    "        \n",
    "        products_scrapped += 1  # Increment the count of products scraped\n",
    "    \n",
    "    # Go to the next page if there are more sneakers\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, '_1LKTO3')\n",
    "        next_button.click()\n",
    "        \n",
    "        # Give time for the page to load\n",
    "        time.sleep(2)\n",
    "        \n",
    "    except:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6306790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Brand                                Product Description  \\\n",
      "0                  BRUTON               Modern Trendy Shoes Sneakers For Men   \n",
      "1                Nobelite                                   Sneakers For Men   \n",
      "2                    PUMA             Puma Rebound LayUp SL Sneakers For Men   \n",
      "3                    aadi  Synthetic Leather |Lightweight|Comfort|Summer|...   \n",
      "4                Schuster                                   Sneakers For Men   \n",
      "..                    ...                                                ...   \n",
      "95                  asian                                   Sneakers For Men   \n",
      "96  HRX by Hrithik Roshan                      Club Culture Sneakers For Men   \n",
      "97                   PUMA                             Caven Sneakers For Men   \n",
      "98                   PUMA                         Hustle V2 Sneakers For Men   \n",
      "99                 Layasa                                   Sneakers For Men   \n",
      "\n",
      "     Price  \n",
      "0     â‚¹379  \n",
      "1     â‚¹299  \n",
      "2   â‚¹3,999  \n",
      "3     â‚¹398  \n",
      "4     â‚¹549  \n",
      "..     ...  \n",
      "95    â‚¹622  \n",
      "96  â‚¹1,047  \n",
      "97  â‚¹2,079  \n",
      "98  â‚¹1,299  \n",
      "99    â‚¹399  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    'Brand': brands,\n",
    "    'Product Description': descriptions,\n",
    "    'Price': prices\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('sneakers_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30328ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d232ff81",
   "metadata": {},
   "source": [
    "# Q7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b4a85189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "# Search for \"Laptop\"\n",
    "search_input = driver.find_element(By.ID, 'twotabsearchtextbox')\n",
    "search_input.send_keys('Laptop')\n",
    "\n",
    "search_button = driver.find_element(By.ID, 'nav-search-submit-button')\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "dade5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter for \"Intel Core i7\" CPU Type\n",
    "proc_filter = driver.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[7]/span[13]/li/span/a/div/label/i\")\n",
    "proc_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d8b2554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store scraped data\n",
    "titles = []\n",
    "ratings = []\n",
    "prices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c770e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data for the first 10 laptops\n",
    "num_laptops = 10\n",
    "laptops_scrapped = 0\n",
    "while laptops_scrapped < num_laptops:\n",
    "    laptop_elements = driver.find_elements(By.XPATH, '//div[@data-asin and @data-component-type=\"s-search-result\"]')\n",
    "    \n",
    "    for laptop_element in laptop_elements:\n",
    "        if laptops_scrapped >= num_laptops:\n",
    "            break  # Exit the loop if 10 laptops have been scraped\n",
    "        \n",
    "        title_element = laptop_element.find_element(By.XPATH, './/h2/a')\n",
    "        title = title_element.text\n",
    "        titles.append(title)\n",
    "        \n",
    "        try:\n",
    "            rating_element = laptop_element.find_element(By.XPATH, './/span[@class=\"a-icon-alt\"]')\n",
    "            rating = rating_element.get_attribute('innerHTML')\n",
    "        except:\n",
    "            rating = 'No Rating'\n",
    "        ratings.append(rating)\n",
    "        \n",
    "        # Locate the price element using the provided tag structure\n",
    "        price_elements = laptop_element.find_elements(By.XPATH, './/span[@class=\"a-price\"]/span[@class=\"a-offscreen\"]')\n",
    "        price = price_elements[0].text if price_elements else 'Price not found'\n",
    "        prices.append(price)\n",
    "        \n",
    "        laptops_scrapped += 1  # Increment the count of laptops scraped\n",
    "    \n",
    "    # Go to the next page if there are more laptops\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CLASS_NAME, 's-pagination-next')\n",
    "        next_button.click()\n",
    "        \n",
    "        # Give time for the page to load\n",
    "        time.sleep(2)\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "599258e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title             Ratings Price\n",
      "0  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...  4.0 out of 5 stars      \n",
      "1  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...  4.5 out of 5 stars      \n",
      "2  Dell Inspiron 5430 13th Gen Laptop, Intel i7-1...  3.3 out of 5 stars      \n",
      "3  ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...           No Rating      \n",
      "4  ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...  4.4 out of 5 stars      \n",
      "5  Dell Vostro 5630 13th Gen Laptop,Intel i7-1355...  4.6 out of 5 stars      \n",
      "6  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...           No Rating      \n",
      "7  ASUS Creator Series Vivobook 14X OLED (2023), ...           No Rating      \n",
      "8  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...  4.3 out of 5 stars      \n",
      "9  HP Victus Gaming Latest 12th Gen Intel Core i7...  4.1 out of 5 stars      \n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    'Title': titles,\n",
    "    'Ratings': ratings,\n",
    "    'Price': prices\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('laptops_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbebb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c50590c",
   "metadata": {},
   "source": [
    "# Q8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ce146303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the webpage\n",
    "driver.get('https://www.azquotes.com/')\n",
    "\n",
    "# Click on Top Quotes\n",
    "top_quotes_button = driver.find_element(By.XPATH, '//a[contains(text(), \"Top Quotes\")]')\n",
    "top_quotes_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a8c6ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "quotes = []\n",
    "authors = []\n",
    "types = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "5e4fdeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll to load more quotes\n",
    "for _ in range(5):  # You can adjust the number of scrolls as needed\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Initialize lists to store data\n",
    "quotes = []\n",
    "authors = []\n",
    "types = []\n",
    "\n",
    "# Scrape data for the top 1000 quotes\n",
    "quote_elements = driver.find_elements(By.CLASS_NAME, 'title')\n",
    "author_elements = driver.find_elements(By.XPATH, '//div[@class=\"author\"]/a')\n",
    "type_elements = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]/a')\n",
    "\n",
    "for quote_element, author_element, type_element in zip(quote_elements, author_elements, type_elements):\n",
    "    quote = quote_element.text\n",
    "    quotes.append(quote)\n",
    "    \n",
    "    author = author_element.text\n",
    "    authors.append(author)\n",
    "    \n",
    "    quote_type = type_element.text\n",
    "    types.append(quote_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "61eb0cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Quote                Author  \\\n",
      "0                                            Authors:        Michael Porter   \n",
      "1   The essence of strategy is choosing what not t...            Golda Meir   \n",
      "2   One cannot and must not try to erase the past ...    Theodore Roosevelt   \n",
      "3   Patriotism means to stand by the country. It d...        Nelson Mandela   \n",
      "4   Death is something inevitable. When a man has ...          Erma Bombeck   \n",
      "..                                                ...                   ...   \n",
      "95  An optimist stays up until midnight to see the...    Hunter S. Thompson   \n",
      "96     When the going gets weird, the weird turn pro.       Corrie Ten Boom   \n",
      "97  When a train goes through a tunnel and it gets...            Dalai Lama   \n",
      "98  If you think you are too small to make a diffe...         Mother Teresa   \n",
      "99  God doesn't require us to succeed, he only req...  Norman Vincent Peale   \n",
      "\n",
      "                 Type  \n",
      "0             Essence  \n",
      "1        Deep Thought  \n",
      "2   Transcendentalism  \n",
      "3         Inspiration  \n",
      "4                Past  \n",
      "..                ...  \n",
      "95            Success  \n",
      "96               Love  \n",
      "97      Inspirational  \n",
      "98               Life  \n",
      "99              Music  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    'Quote': quotes,\n",
    "    'Author': authors,\n",
    "    'Type': types\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('top_quotes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4917cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fd3d35e",
   "metadata": {},
   "source": [
    "# Q9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "bf028150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the webpage\n",
    "driver.get('https://www.jagranjosh.com/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "97f60581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the GK option\n",
    "gk_option = driver.find_element(By.XPATH, '//a[contains(text(), \"GK\")]')\n",
    "gk_option.click()\n",
    "\n",
    "\n",
    "# Click on the List of all Prime Ministers of India\n",
    "prime_ministers_link = driver.find_element(By.XPATH, '//a[contains(text(), \"List of all Prime Ministers of India\")]')\n",
    "prime_ministers_link.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "62571241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store data\n",
    "names = []\n",
    "born_dead = []\n",
    "term_of_office = []\n",
    "remarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "61e4aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data for the list of former Prime Ministers\n",
    "prime_minister_elements = driver.find_elements(By.XPATH, '//div[@class=\"content\"]/ul/li')\n",
    "\n",
    "for prime_minister_element in prime_minister_elements:\n",
    "    details = prime_minister_element.text.split('\\n')\n",
    "    \n",
    "    name = details[0]\n",
    "    names.append(name)\n",
    "    \n",
    "    born_dead_info = details[1]\n",
    "    born_dead.append(born_dead_info)\n",
    "    \n",
    "    term_info = details[2]\n",
    "    term_of_office.append(term_info)\n",
    "    \n",
    "    remark = details[3]\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "128c9e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Born-Dead, Term of Office, Remarks]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    'Name': names,\n",
    "    'Born-Dead': born_dead,\n",
    "    'Term of Office': term_of_office,\n",
    "    'Remarks': remarks\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('prime_ministers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675ca91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50867438",
   "metadata": {},
   "source": [
    "# Q10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e317a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the webpage\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8219bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and interact with the search bar\n",
    "search_bar = driver.find_element(By.ID, \"search_input\")  # Using By.ID to locate the element\n",
    "search_bar.send_keys(\"50 most expensive cars\")  # Input the search query\n",
    "search_bar.send_keys(Keys.RETURN)  # Press Enter to perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2385515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on the '50 most expencive cars in the world' blog\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find the element containing the article content\n",
    "article_content = driver.find_element(By.CLASS_NAME, \"article-content\")\n",
    "\n",
    "# Find car names and prices within the article content\n",
    "car_names = article_content.find_elements(By.TAG_NAME, \"h2\")\n",
    "car_prices = article_content.find_elements(By.CLASS_NAME, \"price\")\n",
    "\n",
    "data = []\n",
    "for name, price in zip(car_names, car_prices):\n",
    "    car_name = name.text\n",
    "    car_price = price.text\n",
    "    data.append({\"Car Name\": car_name, \"Price\": car_price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab54fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DataFrame from the scraped data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
