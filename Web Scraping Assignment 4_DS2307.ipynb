{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90faef82",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment-4\n",
    "## C Soma Sekhar\n",
    "\n",
    "## Batch: DS2307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a12e05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aeb069",
   "metadata": {},
   "source": [
    "## 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "## Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos \n",
    "\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb586b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.29</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.25</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.78</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.38</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.07</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.01</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.53</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.47</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.02</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.96</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.88</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.56</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.43</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.04</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.93</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.86</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.86</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.76</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.70</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.67</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.65</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.58</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.54</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.53</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.51</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.50</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.47</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.45</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.45</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>As of September 2, 2023</td>\n",
       "      <td>As of September 2, 2023</td>\n",
       "      <td>As of September 2, 2023</td>\n",
       "      <td>As of September 2, 2023</td>\n",
       "      <td>As of September 2, 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Rank                                       Name  \\\n",
       "0                        1.                           Baby Shark Dance   \n",
       "1                        2.                                  Despacito   \n",
       "2                        3.                       Johny Johny Yes Papa   \n",
       "3                        4.                                  Bath Song   \n",
       "4                        5.                               Shape of You   \n",
       "5                        6.                              See You Again   \n",
       "6                        7.                          Wheels on the Bus   \n",
       "7                        8.                Phonics Song with Two Words   \n",
       "8                        9.                                Uptown Funk   \n",
       "9                       10.  Learning Colors – Colorful Eggs on a Farm   \n",
       "10                      11.                              Gangnam Style   \n",
       "11                      12.   Masha and the Bear – Recipe for Disaster   \n",
       "12                      13.                             Dame Tu Cosita   \n",
       "13                      14.                                     Axel F   \n",
       "14                      15.                                      Sugar   \n",
       "15                      16.                             Counting Stars   \n",
       "16                      17.                                       Roar   \n",
       "17                      18.                        Baa Baa Black Sheep   \n",
       "18                      19.           Waka Waka (This Time for Africa)   \n",
       "19                      20.                                      Sorry   \n",
       "20                      21.                             Lakdi Ki Kathi   \n",
       "21                      22.                          Thinking Out Loud   \n",
       "22                      23.                                 Dark Horse   \n",
       "23                      24.          Humpty the train on a fruits ride   \n",
       "24                      25.                                    Perfect   \n",
       "25                      26.                                      Faded   \n",
       "26                      27.                                 Let Her Go   \n",
       "27                      28.                             Girls Like You   \n",
       "28                      29.                                    Lean On   \n",
       "29                      30.                                   Bailando   \n",
       "30  As of September 2, 2023                    As of September 2, 2023   \n",
       "\n",
       "                                               Artist  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "1                                          Luis Fonsi   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   \n",
       "3                          Cocomelon - Nursery Rhymes   \n",
       "4                                          Ed Sheeran   \n",
       "5                                         Wiz Khalifa   \n",
       "6                          Cocomelon - Nursery Rhymes   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   \n",
       "8                                         Mark Ronson   \n",
       "9                                         Miroshka TV   \n",
       "10                                        officialpsy   \n",
       "11                                         Get Movies   \n",
       "12                                      Ultra Records   \n",
       "13                                         Crazy Frog   \n",
       "14                                           Maroon 5   \n",
       "15                                        OneRepublic   \n",
       "16                                         Katy Perry   \n",
       "17                         Cocomelon - Nursery Rhymes   \n",
       "18                                            Shakira   \n",
       "19                                      Justin Bieber   \n",
       "20                                       Jingle Toons   \n",
       "21                                         Ed Sheeran   \n",
       "22                                         Katy Perry   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   \n",
       "24                                         Ed Sheeran   \n",
       "25                                        Alan Walker   \n",
       "26                                          Passenger   \n",
       "27                                           Maroon 5   \n",
       "28                               Major Lazer Official   \n",
       "29                                   Enrique Iglesias   \n",
       "30                            As of September 2, 2023   \n",
       "\n",
       "           Views (billions)              Upload Date  \n",
       "0                     13.29            June 17, 2016  \n",
       "1                      8.25         January 12, 2017  \n",
       "2                      6.78          October 8, 2016  \n",
       "3                      6.38              May 2, 2018  \n",
       "4                      6.07         January 30, 2017  \n",
       "5                      6.01            April 6, 2015  \n",
       "6                      5.53             May 24, 2018  \n",
       "7                      5.47            March 6, 2014  \n",
       "8                      5.02        November 19, 2014  \n",
       "9                      4.96        February 27, 2018  \n",
       "10                     4.88            July 15, 2012  \n",
       "11                     4.56         January 31, 2012  \n",
       "12                     4.43            April 5, 2018  \n",
       "13                     4.04            June 16, 2009  \n",
       "14                     3.93         January 14, 2015  \n",
       "15                     3.86             May 31, 2013  \n",
       "16                     3.86        September 5, 2013  \n",
       "17                     3.76            June 25, 2018  \n",
       "18                     3.71             June 4, 2010  \n",
       "19                     3.70         October 22, 2015  \n",
       "20                     3.67            June 14, 2018  \n",
       "21                     3.65          October 7, 2014  \n",
       "22                     3.58        February 20, 2014  \n",
       "23                     3.54         January 26, 2018  \n",
       "24                     3.53         November 9, 2017  \n",
       "25                     3.51         December 3, 2015  \n",
       "26                     3.50            July 25, 2012  \n",
       "27                     3.47             May 31, 2018  \n",
       "28                     3.45           March 22, 2015  \n",
       "29                     3.45           April 11, 2014  \n",
       "30  As of September 2, 2023  As of September 2, 2023  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "\n",
    "# Send an HTTP GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "# Find the table with the specified class\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# pulling out tables\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Removing columns that are not required \n",
    "df = df.drop(['Note', 'Unnamed: 6'], axis =1)\n",
    "\n",
    "#Renaming \n",
    "df.rename(columns = {'No.': 'Rank', 'Video name':'Name', 'Uploader':'Artist','Publication date':'Upload Date'}, inplace = True)\n",
    "\n",
    "# cleaning for name extraction \n",
    "lis = df['Name'].tolist()\n",
    "names = [item.split('[')[0].strip('\"') for item in lis]\n",
    "df['Name'] = names\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('top_youtube_videos.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5adfa",
   "metadata": {},
   "source": [
    "## 2.Scrape the details team India’s international fixtures from bcci.tv.\n",
    "## Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1 ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ceb0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "url2 = 'https://www.bcci.tv/'\n",
    "#url_2t = 'https://www.bcci.tv/international/fixtures'\n",
    "driver.get(url2)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "262b4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the link using XPath\n",
    "link = driver.find_element(By.XPATH,\"//a[@data-event_context='header' and @data-element_text='INTERNATIONAL']\")\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70453bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding more fixtuers \n",
    "try:\n",
    "    while True:\n",
    "        # Find and click the button using XPath\n",
    "        more_fixtures_button = driver.find_element(By.XPATH, \"//button[@class='match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3']\")\n",
    "        more_fixtures_button.click()\n",
    "except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26ef8cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 ['AUSTRALIA TOUR OF INDIA 2023-24', '19TH ASIAN GAMES HANGZHOU 2022', 'AUSTRALIA TOUR OF INDIA 2023-24', 'AUSTRALIA TOUR OF INDIA 2023-24', 'ICC MENS WORLD CUP 2023 WARM-UP MATCHES', '19TH ASIAN GAMES HANGZHOU 2022', 'ICC MENS WORLD CUP 2023 WARM-UP MATCHES', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'ICC MENS WORLD CUP 2023', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'AUSTRALIA TOUR OF INDIA 2023-24', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'AUSTRALIA TOUR OF INDIA 2023-24', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'QUADRANGULAR MENS U19 ONE DAY SERIES', 'AUSTRALIA TOUR OF INDIA 2023-24', 'AUSTRALIA TOUR OF INDIA 2023-24', 'AUSTRALIA TOUR OF INDIA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'INDIA TOUR OF SOUTH AFRICA 2023-24', 'AFGHANISTAN TOUR OF INDIA 2023-24', 'AFGHANISTAN TOUR OF INDIA 2023-24', 'AFGHANISTAN TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24', 'ENGLAND TOUR OF INDIA 2023-24']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store Match_title\n",
    "Match_title = []\n",
    "\n",
    "# Define the number of retries\n",
    "max_retries = 3\n",
    "\n",
    "for retry in range(max_retries):\n",
    "    try:\n",
    "        # Find the elements again within the loop\n",
    "        tm = driver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "        \n",
    "        # Iterate through the elements and append the text to the list\n",
    "        for i in tm:\n",
    "            if i.text is None:\n",
    "                Match_title.append(\"--\")\n",
    "            else:\n",
    "                Match_title.append(i.text)\n",
    "        \n",
    "        # If successful, break out of the loop\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        # Handle the StaleElementReferenceException by refreshing the page\n",
    "        driver.refresh()\n",
    "        \n",
    "   #Print the length and content of Match_title\n",
    "print(len(Match_title), Match_title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "064c4165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 ['22 SEP 2023', '24 SEP 2023', '24 SEP 2023', '27 SEP 2023', '30 SEP 2023', '3 OCT 2023', '3 OCT 2023', '8 OCT 2023', '11 OCT 2023', '14 OCT 2023', '19 OCT 2023', '22 OCT 2023', '29 OCT 2023', '2 NOV 2023', '5 NOV 2023', '12 NOV 2023', '13 NOV 2023', '13 NOV 2023', '15 NOV 2023', '15 NOV 2023', '17 NOV 2023', '17 NOV 2023', '20 NOV 2023', '20 NOV 2023', '22 NOV 2023', '22 NOV 2023', '23 NOV 2023', '24 NOV 2023', '24 NOV 2023', '26 NOV 2023', '27 NOV 2023', '27 NOV 2023', '28 NOV 2023', '1 DEC 2023', '3 DEC 2023', '10 DEC 2023', '12 DEC 2023', '14 DEC 2023', '17 DEC 2023', '19 DEC 2023', '21 DEC 2023', '26 DEC 2023', '3 JAN 2024', '11 JAN 2024', '14 JAN 2024', '17 JAN 2024', '25 JAN 2024', '2 FEB 2024', '15 FEB 2024', '23 FEB 2024', '7 MAR 2024']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store Date\n",
    "Date = []\n",
    "# Define the number of retries\n",
    "max_retries = 3\n",
    "\n",
    "for retry in range(max_retries):\n",
    "    try:\n",
    "        # Find the elements again within the loop\n",
    "        d = driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "        \n",
    "        # Iterate through the elements and append the text to the list\n",
    "        for i in d:\n",
    "            if i.text is None:\n",
    "                Date.append(\"--\")\n",
    "            else:\n",
    "                Date.append(i.text)\n",
    "        \n",
    "        # If successful, break out of the loop\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        # Handle the StaleElementReferenceException by refreshing the page\n",
    "        driver.refresh()\n",
    "print(len(Date), Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92794c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 ['1:30 PM IST', '6:30 AM IST', '1:30 PM IST', '1:30 PM IST', '2:00 PM IST', '6:30 AM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '9:00 AM IST', '7:00 PM IST', '9:00 AM IST', '9:00 AM IST', '7:00 PM IST', '9:00 AM IST', '9:00 AM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '9:30 PM IST', '9:30 PM IST', '9:30 PM IST', '2:00 PM IST', '2:00 PM IST', '2:00 PM IST', '1:30 PM IST', '1:30 PM IST', '7:00 PM IST', '7:00 PM IST', '7:00 PM IST', '9:30 AM IST', '9:30 AM IST', '9:30 AM IST', '9:30 AM IST', '9:30 AM IST']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store Time\n",
    "Time = []\n",
    "# Define the number of retries\n",
    "max_retries = 3\n",
    "\n",
    "for retry in range(max_retries):\n",
    "    try:\n",
    "        # Find the elements again within the loop\n",
    "        t = driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "        \n",
    "        # Iterate through the elements and append the text to the list\n",
    "        for i in t:\n",
    "            if i.text is None:\n",
    "                Time.append(\"--\")\n",
    "            else:\n",
    "                Time.append(i.text)\n",
    "        \n",
    "        # If successful, break out of the loop\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        # Handle the StaleElementReferenceException by refreshing the page\n",
    "        driver.refresh()\n",
    "print(len(Time), Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7469dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 ['1st ODI -', 'Semi Final 1 -', '2nd ODI -', '3rd ODI -', '1st ODI -', 'Quarter Final 1 -', '2nd ODI -', '1st ODI -', '2nd ODI -', '3rd ODI -', '4th ODI -', '5th ODI -', '6th ODI -', '7th ODI -', '8th ODI -', '9th ODI -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', 'Youth List-A Match -', '1st T20I -', 'Youth List-A Match -', 'Youth List-A Match -', '2nd T20I -', '3rd Place -', 'Final -', '3rd T20I -', '4th T20I -', '5th T20I -', '1st T20I -', '2nd T20I -', '3rd T20I -', '1st ODI -', '2nd ODI -', '3rd ODI -', '1st Test -', '2nd Test -', '1st T20I -', '2nd T20I -', '3rd T20I -', '1st Test -', '2nd Test -', '3rd Test -', '4th Test -', '5th Test -']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store Series\n",
    "Series = []\n",
    "# Define the number of retries\n",
    "max_retries = 3\n",
    "\n",
    "for retry in range(max_retries):\n",
    "    try:\n",
    "        # Find the elements again within the loop\n",
    "        s = driver.find_elements(By.XPATH, '//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "        \n",
    "        # Iterate through the elements and append the text to the list\n",
    "        for i in s:\n",
    "            if i.text is None:\n",
    "                Series.append(\"--\")\n",
    "            else:\n",
    "                Series.append(i.text)\n",
    "        \n",
    "        # If successful, break out of the loop\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        # Handle the StaleElementReferenceException by refreshing the page\n",
    "        driver.refresh()\n",
    "print(len(Series), Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a362e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 ['Mohali', 'Hangzhou', 'Indore', 'Rajkot', 'Guwahati', 'Hangzhou', 'Thiruvananthapuram', 'Chennai', 'Delhi', 'Ahmedabad', 'Pune', 'Dharamsala', 'Lucknow', 'Mumbai', 'Kolkata', 'Bengaluru', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Vijayawada', 'Visakhapatnam', 'Vijayawada', 'Vijayawada', 'Thiruvananthapuram', 'Vijayawada', 'Vijayawada', 'Guwahati', 'Nagpur', 'Hyderabad', 'Durban', 'Gqeberha', 'Johannesburg', 'Johannesburg', 'Gqeberha', 'Paarl', 'Centurion', 'Cape Town', 'Mohali', 'Indore', 'Bengaluru', 'Hyderabad', 'Visakhapatnam', 'Rajkot', 'Ranchi', 'Dharamsala']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store Series\n",
    "Place = []\n",
    "# Define the number of retries\n",
    "max_retries = 3\n",
    "\n",
    "for retry in range(max_retries):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Find the elements again within the loop\n",
    "        p = driver.find_elements(By.XPATH, '//span[@class=\"ng-binding\"]')\n",
    "        \n",
    "        # Iterate through the elements and append the text to the list\n",
    "        for i in p:\n",
    "            if i.text is None:\n",
    "                Place.append(\"--\")\n",
    "            else:\n",
    "                Place.append(i.text)\n",
    "        \n",
    "        # If successful, break out of the loop\n",
    "        break\n",
    "    except StaleElementReferenceException:\n",
    "        # Handle the StaleElementReferenceException by refreshing the page\n",
    "        driver.refresh()\n",
    "        \n",
    "print(len(Place), Place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c788ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19TH ASIAN GAMES HANGZHOU 2022</td>\n",
       "      <td>Semi Final 1 -</td>\n",
       "      <td>Hangzhou</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Indore</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Guwahati</td>\n",
       "      <td>30 SEP 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19TH ASIAN GAMES HANGZHOU 2022</td>\n",
       "      <td>Quarter Final 1 -</td>\n",
       "      <td>Hangzhou</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Thiruvananthapuram</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>11 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>14 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>4th ODI -</td>\n",
       "      <td>Pune</td>\n",
       "      <td>19 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>5th ODI -</td>\n",
       "      <td>Dharamsala</td>\n",
       "      <td>22 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>6th ODI -</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>29 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>7th ODI -</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>8th ODI -</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>5 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>9th ODI -</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>13 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>13 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>15 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>15 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>17 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>17 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>20 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>20 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>22 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>22 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>23 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>24 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Youth List-A Match -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>24 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>Thiruvananthapuram</td>\n",
       "      <td>26 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>3rd Place -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>27 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Final -</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>27 NOV 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>Guwahati</td>\n",
       "      <td>28 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>4th T20I -</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>1 DEC 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>5th T20I -</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>3 DEC 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Durban</td>\n",
       "      <td>10 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>Gqeberha</td>\n",
       "      <td>12 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>14 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>17 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Gqeberha</td>\n",
       "      <td>19 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Paarl</td>\n",
       "      <td>21 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>1st Test -</td>\n",
       "      <td>Centurion</td>\n",
       "      <td>26 DEC 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>3 JAN 2024</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>11 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>Indore</td>\n",
       "      <td>14 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>17 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st Test -</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>25 JAN 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>2 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd Test -</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>15 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>4th Test -</td>\n",
       "      <td>Ranchi</td>\n",
       "      <td>23 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>5th Test -</td>\n",
       "      <td>Dharamsala</td>\n",
       "      <td>7 MAR 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Match_title                Series  \\\n",
       "0           AUSTRALIA TOUR OF INDIA 2023-24             1st ODI -   \n",
       "1            19TH ASIAN GAMES HANGZHOU 2022        Semi Final 1 -   \n",
       "2           AUSTRALIA TOUR OF INDIA 2023-24             2nd ODI -   \n",
       "3           AUSTRALIA TOUR OF INDIA 2023-24             3rd ODI -   \n",
       "4   ICC MENS WORLD CUP 2023 WARM-UP MATCHES             1st ODI -   \n",
       "5            19TH ASIAN GAMES HANGZHOU 2022     Quarter Final 1 -   \n",
       "6   ICC MENS WORLD CUP 2023 WARM-UP MATCHES             2nd ODI -   \n",
       "7                   ICC MENS WORLD CUP 2023             1st ODI -   \n",
       "8                   ICC MENS WORLD CUP 2023             2nd ODI -   \n",
       "9                   ICC MENS WORLD CUP 2023             3rd ODI -   \n",
       "10                  ICC MENS WORLD CUP 2023             4th ODI -   \n",
       "11                  ICC MENS WORLD CUP 2023             5th ODI -   \n",
       "12                  ICC MENS WORLD CUP 2023             6th ODI -   \n",
       "13                  ICC MENS WORLD CUP 2023             7th ODI -   \n",
       "14                  ICC MENS WORLD CUP 2023             8th ODI -   \n",
       "15                  ICC MENS WORLD CUP 2023             9th ODI -   \n",
       "16     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "17     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "18     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "19     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "20     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "21     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "22     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "23     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "24     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "25     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "26          AUSTRALIA TOUR OF INDIA 2023-24            1st T20I -   \n",
       "27     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "28     QUADRANGULAR MENS U19 ONE DAY SERIES  Youth List-A Match -   \n",
       "29          AUSTRALIA TOUR OF INDIA 2023-24            2nd T20I -   \n",
       "30     QUADRANGULAR MENS U19 ONE DAY SERIES           3rd Place -   \n",
       "31     QUADRANGULAR MENS U19 ONE DAY SERIES               Final -   \n",
       "32          AUSTRALIA TOUR OF INDIA 2023-24            3rd T20I -   \n",
       "33          AUSTRALIA TOUR OF INDIA 2023-24            4th T20I -   \n",
       "34          AUSTRALIA TOUR OF INDIA 2023-24            5th T20I -   \n",
       "35       INDIA TOUR OF SOUTH AFRICA 2023-24            1st T20I -   \n",
       "36       INDIA TOUR OF SOUTH AFRICA 2023-24            2nd T20I -   \n",
       "37       INDIA TOUR OF SOUTH AFRICA 2023-24            3rd T20I -   \n",
       "38       INDIA TOUR OF SOUTH AFRICA 2023-24             1st ODI -   \n",
       "39       INDIA TOUR OF SOUTH AFRICA 2023-24             2nd ODI -   \n",
       "40       INDIA TOUR OF SOUTH AFRICA 2023-24             3rd ODI -   \n",
       "41       INDIA TOUR OF SOUTH AFRICA 2023-24            1st Test -   \n",
       "42       INDIA TOUR OF SOUTH AFRICA 2023-24            2nd Test -   \n",
       "43        AFGHANISTAN TOUR OF INDIA 2023-24            1st T20I -   \n",
       "44        AFGHANISTAN TOUR OF INDIA 2023-24            2nd T20I -   \n",
       "45        AFGHANISTAN TOUR OF INDIA 2023-24            3rd T20I -   \n",
       "46            ENGLAND TOUR OF INDIA 2023-24            1st Test -   \n",
       "47            ENGLAND TOUR OF INDIA 2023-24            2nd Test -   \n",
       "48            ENGLAND TOUR OF INDIA 2023-24            3rd Test -   \n",
       "49            ENGLAND TOUR OF INDIA 2023-24            4th Test -   \n",
       "50            ENGLAND TOUR OF INDIA 2023-24            5th Test -   \n",
       "\n",
       "                 Place         Date         Time  \n",
       "0               Mohali  22 SEP 2023  1:30 PM IST  \n",
       "1             Hangzhou  24 SEP 2023  6:30 AM IST  \n",
       "2               Indore  24 SEP 2023  1:30 PM IST  \n",
       "3               Rajkot  27 SEP 2023  1:30 PM IST  \n",
       "4             Guwahati  30 SEP 2023  2:00 PM IST  \n",
       "5             Hangzhou   3 OCT 2023  6:30 AM IST  \n",
       "6   Thiruvananthapuram   3 OCT 2023  2:00 PM IST  \n",
       "7              Chennai   8 OCT 2023  2:00 PM IST  \n",
       "8                Delhi  11 OCT 2023  2:00 PM IST  \n",
       "9            Ahmedabad  14 OCT 2023  2:00 PM IST  \n",
       "10                Pune  19 OCT 2023  2:00 PM IST  \n",
       "11          Dharamsala  22 OCT 2023  2:00 PM IST  \n",
       "12             Lucknow  29 OCT 2023  2:00 PM IST  \n",
       "13              Mumbai   2 NOV 2023  2:00 PM IST  \n",
       "14             Kolkata   5 NOV 2023  2:00 PM IST  \n",
       "15           Bengaluru  12 NOV 2023  2:00 PM IST  \n",
       "16          Vijayawada  13 NOV 2023  9:00 AM IST  \n",
       "17          Vijayawada  13 NOV 2023  9:00 AM IST  \n",
       "18          Vijayawada  15 NOV 2023  9:00 AM IST  \n",
       "19          Vijayawada  15 NOV 2023  9:00 AM IST  \n",
       "20          Vijayawada  17 NOV 2023  9:00 AM IST  \n",
       "21          Vijayawada  17 NOV 2023  9:00 AM IST  \n",
       "22          Vijayawada  20 NOV 2023  9:00 AM IST  \n",
       "23          Vijayawada  20 NOV 2023  9:00 AM IST  \n",
       "24          Vijayawada  22 NOV 2023  9:00 AM IST  \n",
       "25          Vijayawada  22 NOV 2023  9:00 AM IST  \n",
       "26       Visakhapatnam  23 NOV 2023  7:00 PM IST  \n",
       "27          Vijayawada  24 NOV 2023  9:00 AM IST  \n",
       "28          Vijayawada  24 NOV 2023  9:00 AM IST  \n",
       "29  Thiruvananthapuram  26 NOV 2023  7:00 PM IST  \n",
       "30          Vijayawada  27 NOV 2023  9:00 AM IST  \n",
       "31          Vijayawada  27 NOV 2023  9:00 AM IST  \n",
       "32            Guwahati  28 NOV 2023  7:00 PM IST  \n",
       "33              Nagpur   1 DEC 2023  7:00 PM IST  \n",
       "34           Hyderabad   3 DEC 2023  7:00 PM IST  \n",
       "35              Durban  10 DEC 2023  9:30 PM IST  \n",
       "36            Gqeberha  12 DEC 2023  9:30 PM IST  \n",
       "37        Johannesburg  14 DEC 2023  9:30 PM IST  \n",
       "38        Johannesburg  17 DEC 2023  2:00 PM IST  \n",
       "39            Gqeberha  19 DEC 2023  2:00 PM IST  \n",
       "40               Paarl  21 DEC 2023  2:00 PM IST  \n",
       "41           Centurion  26 DEC 2023  1:30 PM IST  \n",
       "42           Cape Town   3 JAN 2024  1:30 PM IST  \n",
       "43              Mohali  11 JAN 2024  7:00 PM IST  \n",
       "44              Indore  14 JAN 2024  7:00 PM IST  \n",
       "45           Bengaluru  17 JAN 2024  7:00 PM IST  \n",
       "46           Hyderabad  25 JAN 2024  9:30 AM IST  \n",
       "47       Visakhapatnam   2 FEB 2024  9:30 AM IST  \n",
       "48              Rajkot  15 FEB 2024  9:30 AM IST  \n",
       "49              Ranchi  23 FEB 2024  9:30 AM IST  \n",
       "50          Dharamsala   7 MAR 2024  9:30 AM IST  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'Match_title': Match_title,\n",
    "    'Series': Series,\n",
    "    'Place': Place,\n",
    "    'Date': Date,\n",
    "    'Time': Time\n",
    "})\n",
    "\n",
    "# Convert the DataFrame to a CSV file\n",
    "df2.to_csv('matches.csv', index=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd8c2f",
   "metadata": {},
   "source": [
    "## 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "## Url = http://statisticstimes.com/\n",
    "    \n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3848d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "url3 = 'https://statisticstimes.com/'\n",
    "driver.get(url3)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c366abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Economy')]\")\n",
    "button.click()\n",
    "\n",
    "india_link = driver.find_element(By.LINK_TEXT, \"India\")\n",
    "india_link.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2767b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the link using XPath\n",
    "link_xpath = \"//a[contains(@href, 'india/indian-states-gdp.php') and contains(text(), 'GDP of Indian states')]\"\n",
    "link = driver.find_element(By.XPATH,link_xpath)\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78bad489",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State =[]\n",
    "GDP=[]\n",
    "GSDP_Current=[]\n",
    "GSDP_Previous=[]\n",
    "Share=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "899bed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Rank \n",
    "r=driver.find_elements(By.XPATH,\"//td[@class='data1']\")\n",
    "for i in r:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cee4c950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Gujarat', 'Karnataka', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India', 'Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Telangana', 'Andhra Pradesh', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Jharkhand', 'Chhattisgarh', 'Uttarakhand', 'Himachal Pradesh', 'Jammu & Kashmir', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Manipur', 'Sikkim', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India']\n"
     ]
    }
   ],
   "source": [
    "#scraping the State \n",
    "St=driver.find_elements(By.XPATH, \"//td[@class='name']\")\n",
    "for i in St:\n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "print(len(State),State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f024634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['399.921', '247.629', '240.726', '228.290', '226.806', '165.556', '143.179', '131.083', '130.791', '122.977', '118.733', '117.703', '111.519', '80.562', '79.957', '74.098', '47.982', '46.187', '45.145', '37.351', '23.690', '23.369', '11.115', '7.571', '6.397', '5.230', '5.086', '4.363', '4.233', '4.144', '3.737', '3.385', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GDP \n",
    "gdp=driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    if i.text is None :\n",
    "        GDP.append(\"--\") \n",
    "    else:\n",
    "        GDP.append(i.text)\n",
    "print(len(GDP),GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "919c6612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['13.94%', '8.63%', '8.39%', '7.96%', '7.91%', '5.77%', '4.99%', '4.57%', '4.56%', '4.29%', '4.14%', '4.10%', '3.89%', '2.81%', '2.79%', '2.58%', '1.67%', '1.61%', '1.57%', '1.30%', '0.83%', '0.81%', '0.39%', '0.26%', '0.22%', '0.18%', '0.18%', '0.15%', '0.15%', '0.14%', '0.13%', '0.12%', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Share \n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        Share.append(\"--\") \n",
    "    else:\n",
    "        Share.append(i.text)\n",
    "print(len(Share),Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a25ac476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,632,792', '1,630,208', '1,584,764', '1,502,899', '1,493,127', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '487,805', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '34,433', '33,481', '28,723', '27,870', '27,283', '24,603', '22,287', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Current(18-19)\n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Current.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Current.append(i.text)\n",
    "print(len(GSDP_Current),GSDP_Current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f4a2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['-', '1,845,853', '1,687,818', '-', '1,631,977', '1,253,832', '1,020,989', '972,782', '969,604', '906,672', '-', '856,112', '831,610', '611,804', '574,760', '521,275', '-', '329,180', '328,598', '-', '-', '165,472', '80,449', '55,984', '-', '38,253', '36,572', '32,496', '31,790', '-', '-', '26,503', '-']\n"
     ]
    }
   ],
   "source": [
    "#scraping the GSDP_Previous (19-20)\n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[3]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Previous.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Previous.append(i.text)\n",
    "print(len(GSDP_Previous),GSDP_Previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea3d5e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share In GDP</th>\n",
       "      <th>GDP of State</th>\n",
       "      <th>GSDP_Current(18-19)</th>\n",
       "      <th>GSDP_Current(19-20)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Share In GDP GDP of State  \\\n",
       "0     1                Maharashtra       13.94%      399.921   \n",
       "1     2                 Tamil Nadu        8.63%      247.629   \n",
       "2     3              Uttar Pradesh        8.39%      240.726   \n",
       "3     4                    Gujarat        7.96%      228.290   \n",
       "4     5                  Karnataka        7.91%      226.806   \n",
       "5     6                West Bengal        5.77%      165.556   \n",
       "6     7                  Rajasthan        4.99%      143.179   \n",
       "7     8             Andhra Pradesh        4.57%      131.083   \n",
       "8     9                  Telangana        4.56%      130.791   \n",
       "9    10             Madhya Pradesh        4.29%      122.977   \n",
       "10   11                     Kerala        4.14%      118.733   \n",
       "11   12                      Delhi        4.10%      117.703   \n",
       "12   13                    Haryana        3.89%      111.519   \n",
       "13   14                      Bihar        2.81%       80.562   \n",
       "14   15                     Punjab        2.79%       79.957   \n",
       "15   16                     Odisha        2.58%       74.098   \n",
       "16   17                      Assam        1.67%       47.982   \n",
       "17   18               Chhattisgarh        1.61%       46.187   \n",
       "18   19                  Jharkhand        1.57%       45.145   \n",
       "19   20                Uttarakhand        1.30%       37.351   \n",
       "20   21            Jammu & Kashmir        0.83%       23.690   \n",
       "21   22           Himachal Pradesh        0.81%       23.369   \n",
       "22   23                        Goa        0.39%       11.115   \n",
       "23   24                    Tripura        0.26%        7.571   \n",
       "24   25                 Chandigarh        0.22%        6.397   \n",
       "25   26                 Puducherry        0.18%        5.230   \n",
       "26   27                  Meghalaya        0.18%        5.086   \n",
       "27   28                     Sikkim        0.15%        4.363   \n",
       "28   29                    Manipur        0.15%        4.233   \n",
       "29   30                   Nagaland        0.14%        4.144   \n",
       "30   31          Arunachal Pradesh        0.13%        3.737   \n",
       "31   32                    Mizoram        0.12%        3.385   \n",
       "32   33  Andaman & Nicobar Islands            -            -   \n",
       "\n",
       "   GSDP_Current(18-19) GSDP_Current(19-20)  \n",
       "0            2,632,792                   -  \n",
       "1            1,630,208           1,845,853  \n",
       "2            1,584,764           1,687,818  \n",
       "3            1,502,899                   -  \n",
       "4            1,493,127           1,631,977  \n",
       "5            1,089,898           1,253,832  \n",
       "6              942,586           1,020,989  \n",
       "7              862,957             972,782  \n",
       "8              861,031             969,604  \n",
       "9              809,592             906,672  \n",
       "10             781,653                   -  \n",
       "11             774,870             856,112  \n",
       "12             734,163             831,610  \n",
       "13             530,363             611,804  \n",
       "14             526,376             574,760  \n",
       "15             487,805             521,275  \n",
       "16             315,881                   -  \n",
       "17             304,063             329,180  \n",
       "18             297,204             328,598  \n",
       "19             245,895                   -  \n",
       "20             155,956                   -  \n",
       "21             153,845             165,472  \n",
       "22              73,170              80,449  \n",
       "23              49,845              55,984  \n",
       "24              42,114                   -  \n",
       "25              34,433              38,253  \n",
       "26              33,481              36,572  \n",
       "27              28,723              32,496  \n",
       "28              27,870              31,790  \n",
       "29              27,283                   -  \n",
       "30              24,603                   -  \n",
       "31              22,287              26,503  \n",
       "32                   -                   -  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    'Rank': Rank[:33],\n",
    "    'State': State[:33],\n",
    "    'Share In GDP': Share[:33],\n",
    "    'GDP of State': GDP[:33],\n",
    "    'GSDP_Current(18-19)': GSDP_Current[:33],\n",
    "    'GSDP_Current(19-20)': GSDP_Previous[:33]\n",
    "}\n",
    "\n",
    "State_GDP = pd.DataFrame(data)\n",
    "\n",
    "State_GDP.to_csv('State_GDP.csv', index=False)\n",
    "State_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee39a0a",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com.\n",
    "## Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18e6b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "url4 = 'https://github.com/'\n",
    "driver.get(url4)\n",
    "time.sleep(1)\n",
    "\n",
    "# Navigating to trending page\n",
    "# Find and click the button using XPath\n",
    "button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Open Source')]\")\n",
    "button.click()\n",
    "# Find and click the \"Trending\" link by its text content\n",
    "trending_link = driver.find_element(By.LINK_TEXT, \"Trending\")\n",
    "trending_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b235ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store data\n",
    "Repository_title = []\n",
    "Repository_description = []\n",
    "Contributors_count = []\n",
    "Language = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99dea6f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Locate and iterate through the repository elements\n",
    "repository_elements = driver.find_elements(By.XPATH, \"//article[@class='Box-row']\")\n",
    "for repo in repository_elements:\n",
    "    \n",
    "    #Title\n",
    "    title_element = repo.find_element(By.XPATH, './/h2[@class=\"h3 lh-condensed\"]')\n",
    "        \n",
    "\n",
    "\n",
    "    # Append data to respective lists\n",
    "    Repository_title.append(title_element.text.strip())\n",
    "   \n",
    "\n",
    "    #Language\n",
    "    try:\n",
    "        language_element = repo.find_element(By.XPATH, './/span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "    except:\n",
    "        language_element = None\n",
    "        \n",
    "    if language_element:\n",
    "        Language.append(language_element.text.strip())\n",
    "    else:\n",
    "        Language.append('NA')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889707b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description\n",
    "# Locate and iterate through the repository elements\n",
    "repository_elements = driver.find_elements(By.XPATH, \"//article[@class='Box-row']\")\n",
    "for repo in repository_elements:\n",
    "\n",
    "    try:\n",
    "        desc = repo.find_element(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    except:\n",
    "        desc = None\n",
    "    \n",
    "    if desc:\n",
    "        Repository_description.append(language_element.text.strip())\n",
    "    else:\n",
    "        Repository_description.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684b2e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 2, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 2, 3, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "#Contributors count \n",
    "# Find all repository elements\n",
    "repository_elements = driver.find_elements(By.XPATH, \"//article[@class='Box-row']\")\n",
    "\n",
    "# Initialize a list to store contributor counts\n",
    "contributor_counts = []\n",
    "\n",
    "for repo_element in repository_elements:\n",
    "    try:\n",
    "        # Locate the contributor count element\n",
    "        contributor_element = repo_element.find_element(By.XPATH, \".//span[contains(text(), 'Built by')]\")\n",
    "\n",
    "        # Find all occurrences of class \"d-inline-block\" under \"Built by\"\n",
    "        d_inline_block_elements = contributor_element.find_elements(By.CLASS_NAME, \"d-inline-block\")\n",
    "        \n",
    "        # Count the total occurrences\n",
    "        total_count = len(d_inline_block_elements)\n",
    "        \n",
    "        # Append the total count to the list\n",
    "        contributor_counts.append(total_count)\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        # Handle the case where \"Built by\" or contributor count is missing\n",
    "        contributor_counts.append(None)\n",
    "\n",
    "# Print the list of contributor counts\n",
    "print(contributor_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc4e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contributor_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b700073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opentofu / opentofu</td>\n",
       "      <td>5</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ProjectUnifree / unifree</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>williamyang1991 / Rerender_A_Video</td>\n",
       "      <td>2</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PowerShell / PowerShell</td>\n",
       "      <td>5</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CorentinJ / Real-Time-Voice-Cloning</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mastodon / mastodon</td>\n",
       "      <td>5</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NExT-GPT / NExT-GPT</td>\n",
       "      <td>4</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WooooDyy / LLM-Agent-Paper-List</td>\n",
       "      <td>5</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daveshap / ACE_Framework</td>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coqui-ai / TTS</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>makeplane / plane</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nolimits4web / swiper</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>basecamp / kamal</td>\n",
       "      <td>5</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sczhou / ProPainter</td>\n",
       "      <td>2</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>coder2gwy / coder2gwy</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vercel / next.js</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>meshery / meshery</td>\n",
       "      <td>5</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>usememos / memos</td>\n",
       "      <td>5</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aiwaves-cn / agents</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D4RK-R4BB1T / Dark-Web-Archives</td>\n",
       "      <td>2</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hyperdxio / hyperdx</td>\n",
       "      <td>2</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fmtlib / fmt</td>\n",
       "      <td>5</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ripienaar / free-for-dev</td>\n",
       "      <td>5</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>public-apis / public-apis</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>zhudotexe / kani</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Repository_title  Contributors_count          Language\n",
       "0                   opentofu / opentofu                   5                Go\n",
       "1              ProjectUnifree / unifree                   5            Python\n",
       "2    williamyang1991 / Rerender_A_Video                   2  Jupyter Notebook\n",
       "3               PowerShell / PowerShell                   5                C#\n",
       "4   CorentinJ / Real-Time-Voice-Cloning                   5            Python\n",
       "5                   mastodon / mastodon                   5              Ruby\n",
       "6                   NExT-GPT / NExT-GPT                   4            Python\n",
       "7       WooooDyy / LLM-Agent-Paper-List                   5                NA\n",
       "8              daveshap / ACE_Framework                   2                NA\n",
       "9                        coqui-ai / TTS                   5            Python\n",
       "10                    makeplane / plane                   5        TypeScript\n",
       "11                nolimits4web / swiper                   5        JavaScript\n",
       "12                     basecamp / kamal                   5              Ruby\n",
       "13                  sczhou / ProPainter                   2            Python\n",
       "14                coder2gwy / coder2gwy                   3                NA\n",
       "15                     vercel / next.js                   5        JavaScript\n",
       "16                    meshery / meshery                   5                Go\n",
       "17                     usememos / memos                   5                Go\n",
       "18                  aiwaves-cn / agents                   5            Python\n",
       "19      D4RK-R4BB1T / Dark-Web-Archives                   2               PHP\n",
       "20                  hyperdxio / hyperdx                   2        TypeScript\n",
       "21                         fmtlib / fmt                   5               C++\n",
       "22             ripienaar / free-for-dev                   5              HTML\n",
       "23            public-apis / public-apis                   5            Python\n",
       "24                     zhudotexe / kani                   5            Python"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame\n",
    "df4 = pd.DataFrame({\n",
    "    'Repository_title': Repository_title,\n",
    "    'Contributors_count': contributor_counts,\n",
    "    'Language': Language\n",
    "})\n",
    "\n",
    "#\n",
    "# Print the DataFrame\n",
    "df4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "af56639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('Github_trending.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efcb9ae",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com.\n",
    "## Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb70a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "url5 = 'http://www.billboard.com/'\n",
    "\n",
    "driver.get(url5)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a79e02f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "element = driver.find_element(By.XPATH, \"//button[contains(@class, 'js-MegaMenu-Trigger')]\")\n",
    "element.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03c3adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_100 = driver.find_element(By.XPATH, \"//a[contains(@href, '/charts/hot-100/') and contains(text(), 'Hot 100')]\")\n",
    "hot_100.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "028dc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for serial number\n",
    "# //span[@class=\"c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet\"]\n",
    "#for 1st name\n",
    "# song name:\n",
    "# artist name:\n",
    "\n",
    "#From 2nd-100\n",
    "#song name : //h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]\n",
    "# Artist name: //span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]\n",
    "\n",
    "# last week & Week on b ://li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]\n",
    "#slipt it into 2 parts\n",
    "\n",
    "#2nd part of it is peak rank\n",
    "# peak rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3501458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Vampire', 'Paint The Town Red', 'I Remember Everything', 'Fast Car', 'Cruel Summer', 'Last Night', 'Bad Idea Right?', 'Snooze', 'Fukumean', 'Dance The Night', 'Get Him Back!', 'Calm Down', 'All-American Bitch', 'Bongos', 'Barbie World', 'The Grudge', 'Flowers', 'All My Life', 'Making The Bed', 'Logical', 'Religiously', 'Rich Men North Of Richmond', 'Lacy', 'Ballad Of A Homeschooled Girl', 'Love Is Embarrassing', 'Used To Be Young', \"Thinkin' Bout Me\", 'Need A Favor', 'Kill Bill', \"Pretty Isn't Pretty\", 'Anti-Hero', 'What Was I Made For?', 'Peaches & Eggplants', 'Hey Driver', \"Creepin'\", 'Karma', 'Meltdown', 'Dial Drunk', 'Teenage Dream', 'Watermelon Moonshine', 'I Know ?', 'Qlona', 'Try That In A Small Town', 'Seven', 'Tourniquet', 'What It Is (Block Boy)', 'Single Soon', 'Daylight', 'Love You Anyway', 'Bury Me In Georgia', 'Slow Dancing', 'Spotless', 'Lady Gaga', 'Mi Ex Tenia Razon', 'East Side Of Sorrow', 'Save Me', 'LaLa', 'Good Good', 'In Your Love', 'Bipolar', 'White Horse', 'Last Time I Saw You', 'Telekinesis', 'FE!N', 'Popular', 'SkeeYee', 'Everything I Love', 'Que Onda', \"Angels Don't Always Have Wings\", 'Lose Control', 'Deli', 'Tulum', 'Truck Bed', 'Sabor Fresa', \"Fear And Friday's\", 'El Dorado', 'Johnny Dang', 'Oh U Went', 'Put It On Da Floor Again', 'Where She Goes', 'Ticking', \"Summertime's Close\", 'Dawns', 'Oklahoma Smoke Show', 'Call Your Friends', 'Overtime', 'Pretty Little Poison', 'Come See Me', 'El Amor de Su Vida', 'Holy Roller', 'Girl In Mine', 'Smaller Acts', 'Fight The Feeling', 'K-POP', 'Summer Too Hot', 'Lagunas', \"Sittin' On Top Of The World\", 'Rubicon', 'TQM', 'Amargura']\n",
      "100 ['Olivia Rodrigo', 'Doja Cat', 'Zach Bryan Featuring Kacey Musgraves', 'Luke Combs', 'Taylor Swift', 'Morgan Wallen', 'Olivia Rodrigo', 'SZA', 'Gunna', 'Dua Lipa', 'Olivia Rodrigo', 'Rema & Selena Gomez', 'Olivia Rodrigo', 'Cardi B & Megan Thee Stallion', 'Nicki Minaj & Ice Spice With Aqua', 'Olivia Rodrigo', 'Miley Cyrus', 'Lil Durk Featuring J. Cole', 'Olivia Rodrigo', 'Olivia Rodrigo', 'Bailey Zimmerman', 'Oliver Anthony Music', 'Olivia Rodrigo', 'Olivia Rodrigo', 'Olivia Rodrigo', 'Miley Cyrus', 'Morgan Wallen', 'Jelly Roll', 'SZA', 'Olivia Rodrigo', 'Taylor Swift', 'Billie Eilish', 'Young Nudy Featuring 21 Savage', 'Zach Bryan Featuring The War And Treaty', 'Metro Boomin, The Weeknd & 21 Savage', 'Taylor Swift Featuring Ice Spice', 'Travis Scott Featuring Drake', 'Noah Kahan With Post Malone', 'Olivia Rodrigo', 'Lainey Wilson', 'Travis Scott', 'Karol G & Peso Pluma', 'Jason Aldean', 'Jung Kook Featuring Latto', 'Zach Bryan', 'Doechii Featuring Kodak Black', 'Selena Gomez', 'David Kushner', 'Luke Combs', 'Kane Brown', 'V', 'Zach Bryan Featuring The Lumineers', 'Peso Pluma, Gabito Ballesteros & Junior H', 'Karol G', 'Zach Bryan', 'Jelly Roll With Lainey Wilson', 'Myke Towers', 'Usher, Summer Walker & 21 Savage', 'Tyler Childers', 'Peso Pluma x Jasiel Nunez x Junior H', 'Chris Stapleton', 'Nicki Minaj', 'Travis Scott Featuring SZA & Future', 'Travis Scott Featuring Playboi Carti', 'The Weeknd, Playboi Carti & Madonna', 'Sexyy Red', 'Morgan Wallen', 'Calle 24 x Chino Pacas x Fuerza Regida', 'Thomas Rhett', 'Teddy Swims', 'Ice Spice', 'Peso Pluma & Grupo Frontera', 'HARDY', 'Fuerza Regida', 'Zach Bryan', 'Zach Bryan', 'That Mexican OT, Paul Wall & DRODi', 'Young Thug Featuring Drake', 'Latto Featuring Cardi B', 'Bad Bunny', 'Zach Bryan', 'Zach Bryan', 'Zach Bryan Featuring Maggie Rogers', 'Zach Bryan', 'Rod Wave', 'Zach Bryan', 'Warren Zeiders', 'Rod Wave', 'Grupo Frontera & Grupo Firme', 'Zach Bryan Featuring Sierra Ferrell', 'Parmalee', 'Zach Bryan', 'Rod Wave', 'Travis Scott, Bad Bunny & The Weeknd', 'Chris Brown', 'Peso Pluma & Jasiel Nunez', 'Burna Boy', 'Peso Pluma', 'Fuerza Regida', 'Karol G']\n"
     ]
    }
   ],
   "source": [
    "# intialize varibles list\n",
    "Song_Name =[]\n",
    "Artist_name=[]\n",
    "\n",
    "\n",
    "# exception for 1st one\n",
    "sn1 = driver.find_element(By.XPATH, \"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\").text\n",
    "Song_Name.append(sn1)\n",
    "\n",
    "s1 = driver.find_element(By.XPATH, '//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]').text\n",
    "Artist_name.append(s1)\n",
    "\n",
    "\n",
    "# from 2-100\n",
    "\n",
    "\n",
    "#scraping the Song_Name \n",
    "sn=driver.find_elements(By.XPATH, ' //h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in sn:\n",
    "    if i.text is None :\n",
    "        Song_Name.append(\"--\") \n",
    "    else:\n",
    "        Song_Name.append(i.text)\n",
    "\n",
    "\n",
    "#scraping the Artist Name\n",
    "an=driver.find_elements(By.XPATH, '//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in an:\n",
    "    if i.text is None :\n",
    "        Artist_name.append(\"--\") \n",
    "    else:\n",
    "        Artist_name.append(i.text)\n",
    "\n",
    "print(len(Song_Name),Song_Name)\n",
    "print(len(Artist_name),Artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "331fbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Week: ['9', '1', '2', '3', '4', '5', '26', '7', '8', '6', '-', '10', '-', '-', '12', '-', '13', '14', '-', '-', '15', '11', '-', '-', '-', '16', '19', '18', '21', '-', '20', '22', '51', '17', '25', '24', '27', '28', '-', '33', '34', '31', '30', '37', '29', '41', '39', '42', '32', '36', '-', '35', '47', '43', '40', '79', '44', '58', '65', '-', '57', '23', '50', '54', '66', '67', '64', '61', '73', '81', '60', '71', '59', '70', '48', '49', '75', '76', '68', '72', '52', '53', '77', '80', '97', '55', '87', '56', '93', '69', '92', '63', '-', '74', '94', '-', '86', '95', '89', '91']\n",
      "Weeks on Board: ['11', '6', '3', '25', '19', '33', '5', '40', '13', '16', '1', '54', '1', '1', '12', '1', '35', '18', '1', '1', '19', '5', '1', '1', '1', '3', '28', '24', '40', '1', '47', '9', '15', '3', '41', '27', '7', '13', '1', '12', '7', '5', '9', '9', '3', '19', '3', '22', '31', '18', '1', '3', '12', '5', '3', '13', '10', '5', '7', '1', '8', '2', '7', '7', '15', '2', '29', '2', '8', '5', '8', '11', '13', '12', '3', '3', '9', '12', '15', '17', '3', '3', '20', '8', '4', '3', '5', '2', '4', '3', '7', '3', '19', '8', '4', '9', '3', '11', '17', '5']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Last_Week Rank & Weeks on board\n",
    "Last_Week=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "temp = []\n",
    "lwr=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]')\n",
    "for i in lwr:\n",
    "    if i.text is None :\n",
    "        temp.append(\"--\") \n",
    "    else:\n",
    "        temp.append(i.text)\n",
    "        \n",
    "# spliting into respective groups\n",
    "\n",
    "for i, value in enumerate(temp):\n",
    "    if i % 2 == 0:\n",
    "        Last_Week.append(value)\n",
    "    else:\n",
    "        Weeks_on_board.append(value) \n",
    "print(\"Last Week:\", Last_Week)\n",
    "print(\"Weeks on Board:\", Weeks_on_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5039ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all elements with the class name 'o-chart-results-list__item'\n",
    "elements = driver.find_elements(By.CLASS_NAME, \"o-chart-results-list__item\")\n",
    "\n",
    "# Initialize a list to store the PEAK POS values\n",
    "peak_pos_list = []\n",
    "\n",
    "# Loop through the elements and extract the PEAK POS value\n",
    "for element in elements:\n",
    "    try:\n",
    "        # Use additional filters to narrow down the selection\n",
    "        if \"a-chart-bg-color\" in element.get_attribute(\"class\"):\n",
    "            peak_pos = element.find_element(By.CLASS_NAME, \"c-label\").text.strip()\n",
    "            peak_pos_list.append(peak_pos)\n",
    "    except:\n",
    "        # Handle the case where the element does not contain the PEAK POS\n",
    "        #peak_pos_list.append(\"-\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "001ad902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '1',\n",
       " '7',\n",
       " '7',\n",
       " '4',\n",
       " '6',\n",
       " '11',\n",
       " '3',\n",
       " '13',\n",
       " '14',\n",
       " '7',\n",
       " '16',\n",
       " '1',\n",
       " '2',\n",
       " '19',\n",
       " '20',\n",
       " '14',\n",
       " '1',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '8',\n",
       " '9',\n",
       " '14',\n",
       " '1',\n",
       " '30',\n",
       " '1',\n",
       " '14',\n",
       " '33',\n",
       " '14',\n",
       " '3',\n",
       " '2',\n",
       " '3',\n",
       " '25',\n",
       " '39',\n",
       " '33',\n",
       " '11',\n",
       " '28',\n",
       " '1',\n",
       " '1',\n",
       " '20',\n",
       " '41',\n",
       " '19',\n",
       " '40',\n",
       " '15',\n",
       " '34',\n",
       " '51',\n",
       " '17',\n",
       " '35',\n",
       " '22',\n",
       " '18',\n",
       " '56',\n",
       " '43',\n",
       " '58',\n",
       " '43',\n",
       " '60',\n",
       " '31',\n",
       " '23',\n",
       " '26',\n",
       " '5',\n",
       " '43',\n",
       " '66',\n",
       " '14',\n",
       " '61',\n",
       " '69',\n",
       " '70',\n",
       " '41',\n",
       " '43',\n",
       " '55',\n",
       " '26',\n",
       " '24',\n",
       " '31',\n",
       " '65',\n",
       " '19',\n",
       " '13',\n",
       " '8',\n",
       " '29',\n",
       " '23',\n",
       " '42',\n",
       " '80',\n",
       " '26',\n",
       " '22',\n",
       " '59',\n",
       " '56',\n",
       " '82',\n",
       " '37',\n",
       " '91',\n",
       " '38',\n",
       " '16',\n",
       " '7',\n",
       " '93',\n",
       " '77',\n",
       " '80',\n",
       " '63',\n",
       " '34',\n",
       " '85']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Peak_rank=[]\n",
    "for i, value in enumerate(peak_pos_list):\n",
    "    if i % 2 == 0:\n",
    "        Peak_rank.append(value)\n",
    "Peak_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "007a5f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last Week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Week on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>Zach Bryan Featuring Kacey Musgraves</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td>-</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sittin' On Top Of The World</td>\n",
       "      <td>Burna Boy</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TQM</td>\n",
       "      <td>Fuerza Regida</td>\n",
       "      <td>89</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Amargura</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song_Name                           Artist_name  \\\n",
       "0                       Vampire                        Olivia Rodrigo   \n",
       "1            Paint The Town Red                              Doja Cat   \n",
       "2         I Remember Everything  Zach Bryan Featuring Kacey Musgraves   \n",
       "3                      Fast Car                            Luke Combs   \n",
       "4                  Cruel Summer                          Taylor Swift   \n",
       "..                          ...                                   ...   \n",
       "95                      Lagunas             Peso Pluma & Jasiel Nunez   \n",
       "96  Sittin' On Top Of The World                             Burna Boy   \n",
       "97                      Rubicon                            Peso Pluma   \n",
       "98                          TQM                         Fuerza Regida   \n",
       "99                     Amargura                               Karol G   \n",
       "\n",
       "   Last Week rank Peak rank Week on Board  \n",
       "0               9         1            11  \n",
       "1               1         1             6  \n",
       "2               2         1             3  \n",
       "3               3         2            25  \n",
       "4               4         3            19  \n",
       "..            ...       ...           ...  \n",
       "95              -        77             9  \n",
       "96             86        80             3  \n",
       "97             95        63            11  \n",
       "98             89        34            17  \n",
       "99             91        85             5  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.DataFrame({\n",
    "    'Song_Name': Song_Name,\n",
    "    'Artist_name': Artist_name,'Last Week rank': Last_Week,'Peak rank':Peak_rank, 'Week on Board':Weeks_on_board })\n",
    "df7.to_csv('top _100_songs.csv',index=False)\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80310150",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels\n",
    "\n",
    "## Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "    \n",
    "    You have to find the following details:\n",
    "        \n",
    "        A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e9125b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                              Title            Author  \\\n",
       "1      1                                  Da Vinci Code,The        Brown, Dan   \n",
       "2      2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3      3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4      4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5      5                               Fifty Shades of Grey      James, E. L.   \n",
       "..   ...                                                ...               ...   \n",
       "96    96                                          Ghost,The    Harris, Robert   \n",
       "97    97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98    98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99    99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "    Volume Sales        Publisher                        Genre  \n",
       "1      5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "2      4,475,152       Bloomsbury           Children's Fiction  \n",
       "3      4,200,654       Bloomsbury           Children's Fiction  \n",
       "4      4,179,479       Bloomsbury           Children's Fiction  \n",
       "5      3,758,936     Random House              Romance & Sagas  \n",
       "..           ...              ...                          ...  \n",
       "96       807,311     Random House   General & Literary Fiction  \n",
       "97       794,201          Penguin        Food & Drink: General  \n",
       "98       792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99       791,507            Orion           Biography: General  \n",
       "100      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the first table in the HTML\n",
    "table = soup.find('table')\n",
    "\n",
    "# Create an empty list to store table data\n",
    "data = []\n",
    "\n",
    "# Iterate through the rows of the table and extract data\n",
    "for row in table.find_all('tr'):\n",
    "    row_data = [cell.get_text(strip=True) for cell in row.find_all(['th', 'td'])]\n",
    "    data.append(row_data)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "\n",
    "# Drop the first row (index 0) from the DataFrame\n",
    "df = df.drop(0)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"Highest_selling_novels.csv\", index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4401839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb082eea",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "## Url = https://www.imdb.com/list/ls095964455/ \n",
    "    \n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65666be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings Votes  \n",
       "0    57 min     9.2  None  \n",
       "1    51 min     8.7  None  \n",
       "2    44 min     8.1  None  \n",
       "3    60 min     7.5  None  \n",
       "4    43 min     7.6  None  \n",
       "..      ...     ...   ...  \n",
       "95   42 min     7.5  None  \n",
       "96   50 min     7.8  None  \n",
       "97   42 min     8.1  None  \n",
       "98   45 min       7  None  \n",
       "99  572 min     8.6  None  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opening chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "url7 = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url7)\n",
    "time.sleep(1)\n",
    "\n",
    "# Scroll down to the \"Load More\" button and click it until all TV series are loaded\n",
    "while True:\n",
    "    try:\n",
    "        load_more_button = driver.find_element(By.XPATH, \"//button[@class='ipl-load-more__button']\")\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)  # Wait for the content to load\n",
    "    except:\n",
    "        break  # Break the loop when no more \"Load More\" button is found\n",
    "\n",
    "# Create empty lists to store data\n",
    "names = []\n",
    "year_spans = []\n",
    "genres = []\n",
    "runtimes = []\n",
    "ratings = []\n",
    "votes = []\n",
    "\n",
    "# Extract details for each TV series\n",
    "tv_series_elements = driver.find_elements(By.XPATH, \"//div[@class='lister-item-content']\")\n",
    "for tv_series_element in tv_series_elements:\n",
    "    name = tv_series_element.find_element(By.XPATH, \".//h3/a\").text\n",
    "    year_span = tv_series_element.find_element(By.XPATH, \".//span[@class='lister-item-year text-muted unbold']\").text\n",
    "    genre = tv_series_element.find_element(By.XPATH, \".//span[@class='genre']\").text\n",
    "    runtime = tv_series_element.find_element(By.XPATH, \".//span[@class='runtime']\").text\n",
    "    rating = tv_series_element.find_element(By.XPATH, \".//span[@class='ipl-rating-star__rating']\").text\n",
    "    \n",
    "    # Handling the \"Votes\" element\n",
    "    try:\n",
    "        vote = tv_series_element.find_element(By.XPATH, \".//span[@name='rk']\").get_attribute(\"data-value\")\n",
    "    except:\n",
    "        vote = None\n",
    "\n",
    "    names.append(name)\n",
    "    year_spans.append(year_span)\n",
    "    genres.append(genre)\n",
    "    runtimes.append(runtime)\n",
    "    ratings.append(rating)\n",
    "    votes.append(vote)\n",
    "\n",
    "# Create a DataFrame to store the scraped data\n",
    "data = {\n",
    "    \"Name\": names,\n",
    "    \"Year Span\": year_spans,\n",
    "    \"Genre\": genres,\n",
    "    \"Run Time\": runtimes,\n",
    "    \"Ratings\": ratings,\n",
    "    \"Votes\": votes\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"imdb_tv_series.csv\", index=False)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5e11b",
   "metadata": {},
   "source": [
    "\n",
    " # 8. Details of Datasets from UCI machine learning repositories.\n",
    "## Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b8157ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "url8 = 'https://archive.ics.uci.edu/'\n",
    "driver.get(url8)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "27c819a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigating to Dataset page\n",
    "\n",
    "# Find and click the by its text content\n",
    "trending_link = driver.find_element(By.LINK_TEXT, \"VIEW DATASETS\")\n",
    "trending_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8cc15fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "Attribute_Type=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell or Box that contains every information : [//div[@class=\"relative col-span-8 sm:col-span-7\"]\n",
    "\n",
    "#Data_name : //a[@class=\"link-hover link text-xl font-semibold\"]\n",
    "#Task : //p[@class=\"truncate\"]\n",
    "\n",
    "#Data_type :\n",
    "#Attribute_type(feature type) :\n",
    "#No_of_instance :\n",
    "#No_of_Attribute(Featurers): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c8bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "57289217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store data\n",
    "Dataset_Name = []\n",
    "summary = []\n",
    "Task = []\n",
    "Data_Type = []\n",
    "No_of_Instances = []\n",
    "No_of_Attribute = []\n",
    "\n",
    "for i in range(0,25):\n",
    "    \n",
    "    f_a = []\n",
    "    four_attr= driver.find_elements(By.XPATH, '//div[@class=\"relative col-span-8 sm:col-span-7\"]')\n",
    "    for i in four_attr:\n",
    "        if i.text is None :\n",
    "            f_a.append(\"--\") \n",
    "        else:\n",
    "            f_a.append(i.text)\n",
    "\n",
    "    # Loop through each data string\n",
    "    for data_string in f_a:\n",
    "        # Split the string by '\\n' to separate the information\n",
    "        data_list = data_string.split('\\n')\n",
    "\n",
    "        # Check if the data string has all the required elements\n",
    "        if len(data_list) >= 6:\n",
    "            Dataset_Name.append(data_list[0])\n",
    "            summary.append(data_list[1])\n",
    "            Task.append(data_list[2])\n",
    "            Data_Type.append(data_list[3])\n",
    "            No_of_Instances.append(data_list[4])\n",
    "            No_of_Attribute.append(data_list[5])\n",
    "        else:\n",
    "            # Handle incomplete data strings, e.g., by appending placeholders or skipping\n",
    "            Dataset_Name.append(\"N/A\")\n",
    "            summary.append(\"N/A\")\n",
    "            Task.append(\"N/A\")\n",
    "            Data_Type.append(\"N/A\")\n",
    "            No_of_Instances.append(\"N/A\")\n",
    "            No_of_Attribute.append(\"N/A\")\n",
    "            \n",
    "    next_page_button = driver.find_element(By.XPATH, \"//button[@aria-label='Next Page']\")\n",
    "    next_page_button.click()\n",
    "    time.sleep(2)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da77a3f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48.84K</td>\n",
       "      <td>14</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13.61K</td>\n",
       "      <td>16</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Thyroid Disease</td>\n",
       "      <td>Multivariate, Domain-Theory</td>\n",
       "      <td>Classification</td>\n",
       "      <td>7.2K</td>\n",
       "      <td>5</td>\n",
       "      <td>10 separate databases from Garavan Institute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Predict students' dropout and academic success</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>4.42K</td>\n",
       "      <td>36</td>\n",
       "      <td>A dataset created from a higher education inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>4.6K</td>\n",
       "      <td>57</td>\n",
       "      <td>Classifying Email as Spam or Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Student Performance</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>649</td>\n",
       "      <td>33</td>\n",
       "      <td>Predict student performance in secondary educa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Credit Approval</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>690</td>\n",
       "      <td>15</td>\n",
       "      <td>This data concerns credit card applications; g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Dataset_Name  \\\n",
       "0                                              Iris   \n",
       "1                                     Heart Disease   \n",
       "2                                             Adult   \n",
       "3                                  Dry Bean Dataset   \n",
       "4                                               N/A   \n",
       "..                                              ...   \n",
       "620                                 Thyroid Disease   \n",
       "621  Predict students' dropout and academic success   \n",
       "622                                        Spambase   \n",
       "623                             Student Performance   \n",
       "624                                 Credit Approval   \n",
       "\n",
       "                       Data_Type                        Task No_of_Instances  \\\n",
       "0                        Tabular              Classification             150   \n",
       "1                   Multivariate              Classification             303   \n",
       "2                   Multivariate              Classification          48.84K   \n",
       "3                   Multivariate              Classification          13.61K   \n",
       "4                            N/A                         N/A             N/A   \n",
       "..                           ...                         ...             ...   \n",
       "620  Multivariate, Domain-Theory              Classification            7.2K   \n",
       "621                      Tabular              Classification           4.42K   \n",
       "622                 Multivariate              Classification            4.6K   \n",
       "623                 Multivariate  Classification, Regression             649   \n",
       "624                 Multivariate              Classification             690   \n",
       "\n",
       "    No_of_Attribute                                            summary  \n",
       "0                 4  A small classic dataset from Fisher, 1936. One...  \n",
       "1                13  4 databases: Cleveland, Hungary, Switzerland, ...  \n",
       "2                14  Predict whether income exceeds $50K/yr based o...  \n",
       "3                16  Images of 13,611 grains of 7 different registe...  \n",
       "4               N/A                                                N/A  \n",
       "..              ...                                                ...  \n",
       "620               5       10 separate databases from Garavan Institute  \n",
       "621              36  A dataset created from a higher education inst...  \n",
       "622              57              Classifying Email as Spam or Non-Spam  \n",
       "623              33  Predict student performance in secondary educa...  \n",
       "624              15  This data concerns credit card applications; g...  \n",
       "\n",
       "[625 rows x 6 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove \" Instances\" and \" Features\" text\n",
    "No_of_Instances = [count.replace(\" Instances\", \"\") for count in No_of_Instances]\n",
    "No_of_Attribute = [count.replace(\" Features\", \"\") for count in No_of_Attribute]\n",
    "\n",
    "# Create a DataFrame\n",
    "df8 = pd.DataFrame({\n",
    "    'Dataset_Name': Dataset_Name,\n",
    "    'Data_Type': Data_Type,\n",
    "    'Task': Task,\n",
    "    'No_of_Instances': No_of_Instances,\n",
    "    'No_of_Attribute': No_of_Attribute,\n",
    "    'summary': summary,\n",
    "})\n",
    "df8.to_csv('UCI_dataset.csv', index = False)\n",
    "# Display the DataFrame\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd376cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
